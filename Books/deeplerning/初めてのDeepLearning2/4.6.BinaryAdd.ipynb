{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 26,
            "source": [
                "import numpy as np\r\n",
                "#import cupy as np\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "\r\n",
                "%matplotlib inline"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "source": [
                "n_time = 8  # 時系列の数\r\n",
                "n_in   = 2   # 入力層ニューロン数\r\n",
                "n_mid  = 32  # 中間層ニューロン数\r\n",
                "n_out  = 1   # 出力層ニューロン数"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "source": [
                "# 学習データ\r\n",
                "max_num = 2**n_time\r\n",
                "binaries = np.zeros((max_num, n_time), dtype=int)\r\n",
                "for i in range(max_num):\r\n",
                "    num10 = i\r\n",
                "    for j in range(n_time):\r\n",
                "        pow2 = 2 ** (n_time - 1 - j)\r\n",
                "        binaries[i, j] = num10 // pow2\r\n",
                "        num10 %= pow2\r\n",
                "\r\n",
                "print(binaries)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[[0 0 0 ... 0 0 0]\n",
                        " [0 0 0 ... 0 0 1]\n",
                        " [0 0 0 ... 0 1 0]\n",
                        " ...\n",
                        " [1 1 1 ... 1 0 1]\n",
                        " [1 1 1 ... 1 1 0]\n",
                        " [1 1 1 ... 1 1 1]]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "source": [
                "eta      = 0.1  # 学習係数\r\n",
                "n_learn = 5001  # 学習回数\r\n",
                "interval = 500  # 経過の表示間隔\r\n",
                "\r\n",
                "\r\n",
                "class OutputLayer:\r\n",
                "    def __init__(self, n_upper, n):\r\n",
                "        self.w = np.random.randn(n_upper, n) / np.sqrt(n_upper)\r\n",
                "        self.b = np.zeros(n)\r\n",
                "    \r\n",
                "    def activate_func(self, u):\r\n",
                "        # sigmoid function\r\n",
                "        return 1 / (1 + np.exp(-u))\r\n",
                "    \r\n",
                "    def diff_func(self, grad_y, y):\r\n",
                "        # differencial sigmoid\r\n",
                "        return grad_y * (1 - y) * y\r\n",
                "    \r\n",
                "    def forward(self, x):\r\n",
                "        self.x = x\r\n",
                "        u = np.dot(x, self.w) + self.b\r\n",
                "        self.y = self.activate_func(u)\r\n",
                "        return self.y\r\n",
                "    \r\n",
                "    def backward(self, x, y, t):\r\n",
                "        delta = self.diff_func(y - t, y)\r\n",
                "        self.grad_w = np.dot(x.T, delta)\r\n",
                "        self.grad_b = np.sum(delta, axis=0)\r\n",
                "        self.grad_x = np.dot(delta, self.w.T)\r\n",
                "        return self.grad_x\r\n",
                "\r\n",
                "    def reset_sum_grad(self):\r\n",
                "        self.grad_w = np.zeros_like(self.w)\r\n",
                "        self.grad_b = np.zeros_like(self.b)\r\n",
                "    \r\n",
                "    def update(self, eta):\r\n",
                "        self.w -= eta * self.grad_w\r\n",
                "        self.b -= eta * self.grad_b\r\n",
                "\r\n",
                "\r\n",
                "\r\n",
                "class RnnBaseLayer:\r\n",
                "    def __init__(self, n_upper, n):\r\n",
                "        self.w = np.random.randn(n_upper, n) / np.sqrt(n_upper)\r\n",
                "        self.v = np.random.randn(n, n) / np.sqrt(n)\r\n",
                "        self.b = np.zeros(n)\r\n",
                "\r\n",
                "    # def activate_func(self, u):\r\n",
                "    #     # simplly tanh\r\n",
                "    #     return np.tanh(u)\r\n",
                "    \r\n",
                "    # def diff_func(self, grad_y, y):\r\n",
                "    #     # differencial sigmoid\r\n",
                "    #     return grad_y * (1 - y) * y\r\n",
                "    \r\n",
                "    def forward(self, x, prev_y):\r\n",
                "        u = np.dot(x, self.w) + np.dot(prev_y, self.v) + self.b\r\n",
                "        self.y = np.tanh(u)\r\n",
                "        return self.y\r\n",
                "    \r\n",
                "    def backward(self, x, y, prev_y, grad_y):\r\n",
                "        delta = grad_y * (1 - y**2)\r\n",
                "\r\n",
                "        self.grad_w += np.dot(x.T, delta)\r\n",
                "        self.grad_v += np.dot(prev_y.T, delta)\r\n",
                "        self.grad_b += np.sum(delta, axis=0)\r\n",
                "\r\n",
                "        self.grad_x = np.dot(delta, self.w.T)\r\n",
                "        self.grad_prev_y = np.dot(delta, self.v.T)\r\n",
                "        return self.grad_prev_y\r\n",
                "\r\n",
                "    def reset_sum_grad(self):\r\n",
                "        self.grad_w = np.zeros_like(self.w)\r\n",
                "        self.grad_v = np.zeros_like(self.v)\r\n",
                "        self.grad_b = np.zeros_like(self.b)\r\n",
                "\r\n",
                "    def update(self, eta):\r\n",
                "        self.w -= eta * self.grad_w\r\n",
                "        self.v -= eta * self.grad_v\r\n",
                "        self.b -= eta * self.grad_b"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "source": [
                "rnnLayer = RnnBaseLayer(n_in, n_mid)\r\n",
                "outputLayer = OutputLayer(n_mid, n_out)\r\n",
                "\r\n",
                "def train(x_mb, t_mb):\r\n",
                "    y_rnn = np.zeros((len(x_mb), n_time+1, n_mid))\r\n",
                "    y_out = np.zeros((len(x_mb), n_time, n_out))\r\n",
                "\r\n",
                "    # Forward propergation\r\n",
                "    y_prev = y_rnn[:, 0, :]\r\n",
                "    for i in range(n_time):\r\n",
                "        # RNN layer\r\n",
                "        x = x_mb[:, i, :]\r\n",
                "        y = rnnLayer.forward(x, y_prev)\r\n",
                "        y_rnn[:, i + 1, :] = y\r\n",
                "        y_prev = y\r\n",
                "\r\n",
                "        # output layer\r\n",
                "        y_out[:, i, :] = outputLayer.forward(y)\r\n",
                "    \r\n",
                "    # back propergation\r\n",
                "    outputLayer.reset_sum_grad()\r\n",
                "    rnnLayer.reset_sum_grad()\r\n",
                "    grad_y = 0\r\n",
                "    for i in reversed(range(n_time)):\r\n",
                "        # output layer\r\n",
                "        x = y_rnn[:, i+1, :]\r\n",
                "        y = y_out[:, i, :]\r\n",
                "        t = t_mb[:, i, :]\r\n",
                "        grad_x_out = outputLayer.backward(x, y, t)\r\n",
                "\r\n",
                "        # Rnn layer\r\n",
                "        x = x_mb[:, i, :]\r\n",
                "        y = y_rnn[:, i+1, :]\r\n",
                "        y_prev = y_rnn[:, i, :]\r\n",
                "        grad_y = rnnLayer.backward(x, y, y_prev, grad_y + grad_x_out)\r\n",
                "\r\n",
                "    # update\r\n",
                "    rnnLayer.update(eta)\r\n",
                "    outputLayer.update(eta)\r\n",
                "    return y_out\r\n",
                "\r\n",
                "def get_error(y, t):\r\n",
                "    return 1.0/2.0*np.sum(np.square(y - t))\r\n",
                "\r\n",
                "for i in range(n_learn):\r\n",
                "    # ランダムなインデックスを作成\r\n",
                "    num1 = np.random.randint(max_num//2)\r\n",
                "    num2 = np.random.randint(max_num//2)\r\n",
                "\r\n",
                "    # これをビット配列に置き換えて\r\n",
                "    x1= binaries[num1]\r\n",
                "    x2= binaries[num2]\r\n",
                "\r\n",
                "    # 引数の形状にまとめる\r\n",
                "    x_in = np.zeros((1, n_time, n_in))\r\n",
                "    x_in[0, :, 0] = x1\r\n",
                "    x_in[0, :, 1] = x2\r\n",
                "    x_in  = np.flip(x_in, axis=1)\r\n",
                "\r\n",
                "    # 結果データ\r\n",
                "    t = binaries[num1+num2]\r\n",
                "    t_in = t.reshape(1, n_time, n_out)\r\n",
                "    t_in = np.flip(t_in , axis=1)\r\n",
                "\r\n",
                "    # 学習\r\n",
                "    y_out = train(x_in, t_in)\r\n",
                "    y = np.flip(y_out, axis=1).reshape(-1)\r\n",
                "\r\n",
                "    error = get_error(y_out, t_in)\r\n",
                "\r\n",
                "    if i % interval == 0:\r\n",
                "        y2 = np.where(y<0.5, 0, 1)\r\n",
                "        y10 = 0\r\n",
                "        for j in range(len(y)):\r\n",
                "            pow2 = 2 ** (n_time-1-j)\r\n",
                "            y10 += y2[j] * pow2\r\n",
                "\r\n",
                "        print(\"learn count:\", i)\r\n",
                "        print(\"error rate:\", error)\r\n",
                "        c = \"Success : \" if (y2 == t).all() else \"Failure : \"\r\n",
                "        print(c + str(num1) + \" + \" + str(num2) + \" = \" + str(y10))\r\n",
                "        print(\"========================\")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "4 + 75 = [0 1 0 0 1 1 1 1]\n",
                        "[[[0.66340282]\n",
                        "  [0.73069887]\n",
                        "  [0.43033845]\n",
                        "  [0.42716919]\n",
                        "  [0.54139796]\n",
                        "  [0.27189093]\n",
                        "  [0.58747427]\n",
                        "  [0.64141235]]]\n",
                        "learn count: 0\n",
                        "error rate: 0.8935469441361628\n",
                        "output : [1 1 0 1 0 0 1 1]\n",
                        "correct: [0 1 0 0 1 1 1 1]\n",
                        "Failure : 4 + 75 = 211\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "24 + 81 = [0 1 1 0 1 0 0 1]\n",
                        "[[[0.74407053]\n",
                        "  [0.30129711]\n",
                        "  [0.20469693]\n",
                        "  [0.61470713]\n",
                        "  [0.33542838]\n",
                        "  [0.65703307]\n",
                        "  [0.54884136]\n",
                        "  [0.29052672]]]\n",
                        "learn count: 500\n",
                        "error rate: 0.43235983550506946\n",
                        "output : [0 1 1 0 1 0 0 1]\n",
                        "correct: [0 1 1 0 1 0 0 1]\n",
                        "Success : 24 + 81 = 105\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "18 + 95 = [0 1 1 1 0 0 0 1]\n",
                        "[[[0.88360746]\n",
                        "  [0.13748579]\n",
                        "  [0.16149205]\n",
                        "  [0.22483156]\n",
                        "  [0.84795271]\n",
                        "  [0.82434239]\n",
                        "  [0.88430351]\n",
                        "  [0.06713049]]]\n",
                        "learn count: 1000\n",
                        "error rate: 0.0904723161200466\n",
                        "output : [0 1 1 1 0 0 0 1]\n",
                        "correct: [0 1 1 1 0 0 0 1]\n",
                        "Success : 18 + 95 = 113\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "22 + 110 = [1 0 0 0 0 1 0 0]\n",
                        "[[[0.06573756]\n",
                        "  [0.08200762]\n",
                        "  [0.90303104]\n",
                        "  [0.11519444]\n",
                        "  [0.16283362]\n",
                        "  [0.1271182 ]\n",
                        "  [0.13754294]\n",
                        "  [0.90043497]]]\n",
                        "learn count: 1500\n",
                        "error rate: 0.052612246945831505\n",
                        "output : [1 0 0 0 0 1 0 0]\n",
                        "correct: [1 0 0 0 0 1 0 0]\n",
                        "Success : 22 + 110 = 132\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "97 + 77 = [1 0 1 0 1 1 1 0]\n",
                        "[[[0.06485928]\n",
                        "  [0.91178162]\n",
                        "  [0.93324494]\n",
                        "  [0.94214001]\n",
                        "  [0.02691125]\n",
                        "  [0.95186318]\n",
                        "  [0.0686568 ]\n",
                        "  [0.9200782 ]]]\n",
                        "learn count: 2000\n",
                        "error rate: 0.01696792200815664\n",
                        "output : [1 0 1 0 1 1 1 0]\n",
                        "correct: [1 0 1 0 1 1 1 0]\n",
                        "Success : 97 + 77 = 174\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "24 + 85 = [0 1 1 0 1 1 0 1]\n",
                        "[[[0.94656383]\n",
                        "  [0.02974323]\n",
                        "  [0.95996481]\n",
                        "  [0.95663365]\n",
                        "  [0.04883819]\n",
                        "  [0.93552407]\n",
                        "  [0.94360036]\n",
                        "  [0.02414914]]]\n",
                        "learn count: 2500\n",
                        "error rate: 0.008764977485041993\n",
                        "output : [0 1 1 0 1 1 0 1]\n",
                        "correct: [0 1 1 0 1 1 0 1]\n",
                        "Success : 24 + 85 = 109\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "98 + 11 = [0 1 1 0 1 1 0 1]\n",
                        "[[[0.95659896]\n",
                        "  [0.04726879]\n",
                        "  [0.93804253]\n",
                        "  [0.95570201]\n",
                        "  [0.02491491]\n",
                        "  [0.96202109]\n",
                        "  [0.96483396]\n",
                        "  [0.01824547]]]\n",
                        "learn count: 3000\n",
                        "error rate: 0.006775863025342371\n",
                        "output : [0 1 1 0 1 1 0 1]\n",
                        "correct: [0 1 1 0 1 1 0 1]\n",
                        "Success : 98 + 11 = 109\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "48 + 8 = [0 0 1 1 1 0 0 0]\n",
                        "[[[0.03010967]\n",
                        "  [0.02150751]\n",
                        "  [0.02726192]\n",
                        "  [0.96123224]\n",
                        "  [0.96656014]\n",
                        "  [0.96579043]\n",
                        "  [0.01971056]\n",
                        "  [0.01513435]]]\n",
                        "learn count: 3500\n",
                        "error rate: 0.0032606952582301205\n",
                        "output : [0 0 1 1 1 0 0 0]\n",
                        "correct: [0 0 1 1 1 0 0 0]\n",
                        "Success : 48 + 8 = 56\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "35 + 83 = [0 1 1 1 0 1 1 0]\n",
                        "[[[0.03858441]\n",
                        "  [0.95729767]\n",
                        "  [0.94485009]\n",
                        "  [0.01222762]\n",
                        "  [0.9704578 ]\n",
                        "  [0.97105742]\n",
                        "  [0.97300371]\n",
                        "  [0.01422545]]]\n",
                        "learn count: 4000\n",
                        "error rate: 0.004572425212733861\n",
                        "output : [0 1 1 1 0 1 1 0]\n",
                        "correct: [0 1 1 1 0 1 1 0]\n",
                        "Success : 35 + 83 = 118\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "2 + 76 = [0 1 0 0 1 1 1 0]\n",
                        "[[[0.02477459]\n",
                        "  [0.96556312]\n",
                        "  [0.97531944]\n",
                        "  [0.98065327]\n",
                        "  [0.01288446]\n",
                        "  [0.01516261]\n",
                        "  [0.97158602]\n",
                        "  [0.00966399]]]\n",
                        "learn count: 4500\n",
                        "error rate: 0.0020398829175778694\n",
                        "output : [0 1 0 0 1 1 1 0]\n",
                        "correct: [0 1 0 0 1 1 1 0]\n",
                        "Success : 2 + 76 = 78\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "64 + 119 = [1 0 1 1 0 1 1 1]\n",
                        "[[[0.96836954]\n",
                        "  [0.96731446]\n",
                        "  [0.9741863 ]\n",
                        "  [0.0128321 ]\n",
                        "  [0.97473707]\n",
                        "  [0.97777953]\n",
                        "  [0.03533688]\n",
                        "  [0.95901271]]]\n",
                        "learn count: 5000\n",
                        "error rate: 0.003480229536650523\n",
                        "output : [1 0 1 1 0 1 1 1]\n",
                        "correct: [1 0 1 1 0 1 1 1]\n",
                        "Success : 64 + 119 = 183\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.8 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "73e03da126b73bfff3642ec5261d56fa25c444ea595de51041687efaa60dda41"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}