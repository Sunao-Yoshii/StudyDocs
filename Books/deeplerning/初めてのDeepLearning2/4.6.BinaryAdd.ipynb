{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import numpy as np\r\n",
                "#import cupy as np\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "\r\n",
                "%matplotlib inline"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "n_time = 8  # 時系列の数\r\n",
                "n_in   = 2   # 入力層ニューロン数\r\n",
                "n_mid  = 32  # 中間層ニューロン数\r\n",
                "n_out  = 1   # 出力層ニューロン数"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "# 学習データ\r\n",
                "\r\n",
                "max_num = 2**n_time\r\n",
                "binaries = np.zeros((max_num, n_time), dtype=int)\r\n",
                "for i in range(max_num):\r\n",
                "    num10 = i\r\n",
                "    for j in range(n_time):\r\n",
                "        pow2 = 2 ** (n_time - 1 - j)\r\n",
                "        binaries[i, j] = num10 // pow2\r\n",
                "        num10 %= pow2\r\n",
                "\r\n",
                "print(binaries)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[[0 0 0 ... 0 0 0]\n",
                        " [0 0 0 ... 0 0 1]\n",
                        " [0 0 0 ... 0 1 0]\n",
                        " ...\n",
                        " [1 1 1 ... 1 0 1]\n",
                        " [1 1 1 ... 1 1 0]\n",
                        " [1 1 1 ... 1 1 1]]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "eta      = 0.1  # 学習係数\r\n",
                "n_learn = 5001  # 学習回数\r\n",
                "interval = 500  # 経過の表示間隔\r\n",
                "\r\n",
                "\r\n",
                "class OutputLayer:\r\n",
                "    def __init__(self, n_upper, n):\r\n",
                "        self.w = np.random.randn(n_upper, n) / np.sqrt(n_upper)\r\n",
                "        self.b = np.zeros(n)\r\n",
                "    \r\n",
                "    def activate_func(self, u):\r\n",
                "        # sigmoid function\r\n",
                "        return 1 / (1 + np.exp(-u))\r\n",
                "    \r\n",
                "    def diff_func(self, grad_y, y):\r\n",
                "        # differencial sigmoid\r\n",
                "        return grad_y * (1 - y) * y\r\n",
                "    \r\n",
                "    def forward(self, x):\r\n",
                "        self.x = x\r\n",
                "        u = np.dot(x, self.w) + self.b\r\n",
                "        self.y = self.activate_func(u)\r\n",
                "        return self.y\r\n",
                "    \r\n",
                "    def backward(self, x, y, t):\r\n",
                "        delta = self.diff_func(y - t, y)\r\n",
                "        self.grad_w = np.dot(x.T, delta)\r\n",
                "        self.grad_b = np.sum(delta, axis=0)\r\n",
                "        self.grad_x = np.dot(delta, self.w.T)\r\n",
                "        return self.grad_x\r\n",
                "\r\n",
                "    def reset_sum_grad(self):\r\n",
                "        self.grad_w = np.zeros_like(self.w)\r\n",
                "        self.grad_b = np.zeros_like(self.b)\r\n",
                "    \r\n",
                "    def update(self, eta):\r\n",
                "        self.w -= eta * self.grad_w\r\n",
                "        self.b -= eta * self.grad_b\r\n",
                "\r\n",
                "\r\n",
                "\r\n",
                "class RnnBaseLayer:\r\n",
                "    def __init__(self, n_upper, n):\r\n",
                "        self.w = np.random.randn(n_upper, n) / np.sqrt(n_upper)\r\n",
                "        self.v = np.random.randn(n, n) / np.sqrt(n)\r\n",
                "        self.b = np.zeros(n)\r\n",
                "\r\n",
                "    # def activate_func(self, u):\r\n",
                "    #     # simplly tanh\r\n",
                "    #     return np.tanh(u)\r\n",
                "    \r\n",
                "    # def diff_func(self, grad_y, y):\r\n",
                "    #     # differencial sigmoid\r\n",
                "    #     return grad_y * (1 - y) * y\r\n",
                "    \r\n",
                "    def forward(self, x, prev_y):\r\n",
                "        u = np.dot(x, self.w) + np.dot(prev_y, self.v) + self.b\r\n",
                "        self.y = np.tanh(u)\r\n",
                "        return self.y\r\n",
                "    \r\n",
                "    def backward(self, x, y, prev_y, grad_y):\r\n",
                "        delta = grad_y * (1 - y**2)\r\n",
                "\r\n",
                "        self.grad_w += np.dot(x.T, delta)\r\n",
                "        self.grad_v += np.dot(prev_y.T, delta)\r\n",
                "        self.grad_b += np.sum(delta, axis=0)\r\n",
                "\r\n",
                "        self.grad_x = np.dot(delta, self.w.T)\r\n",
                "        self.grad_prev_y = np.dot(delta, self.v.T)\r\n",
                "        return self.grad_prev_y\r\n",
                "\r\n",
                "    def reset_sum_grad(self):\r\n",
                "        self.grad_w = np.zeros_like(self.w)\r\n",
                "        self.grad_v = np.zeros_like(self.v)\r\n",
                "        self.grad_b = np.zeros_like(self.b)\r\n",
                "\r\n",
                "    def update(self, eta):\r\n",
                "        self.w -= eta * self.grad_w\r\n",
                "        self.v -= eta * self.grad_v\r\n",
                "        self.b -= eta * self.grad_b"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "rnnLayer = RnnBaseLayer(n_in, n_mid)\r\n",
                "outputLayer = OutputLayer(n_mid, n_out)\r\n",
                "\r\n",
                "def train(x_mb, t_mb):\r\n",
                "    y_rnn = np.zeros((len(x_mb), n_time+1, n_mid))\r\n",
                "    y_out = np.zeros((len(x_mb), n_time, n_out))\r\n",
                "\r\n",
                "    # Forward propergation\r\n",
                "    y_prev = y_rnn[:, 0, :]\r\n",
                "    for i in range(n_time):\r\n",
                "        # RNN layer\r\n",
                "        x = x_mb[:, i, :]\r\n",
                "        y = rnnLayer.forward(x, y_prev)\r\n",
                "        y_rnn[:, i + 1, :] = y\r\n",
                "        y_prev = y\r\n",
                "\r\n",
                "        # output layer\r\n",
                "        y_out[:, i, :] = outputLayer.forward(y)\r\n",
                "    \r\n",
                "    # back propergation\r\n",
                "    outputLayer.reset_sum_grad()\r\n",
                "    rnnLayer.reset_sum_grad()\r\n",
                "    grad_y = 0\r\n",
                "    for i in reversed(range(n_time)):\r\n",
                "        # output layer\r\n",
                "        x = y_rnn[:, i+1, :]\r\n",
                "        y = y_out[:, i, :]\r\n",
                "        t = t_mb[:, i, :]\r\n",
                "        grad_x_out = outputLayer.backward(x, y, t)\r\n",
                "\r\n",
                "        # Rnn layer\r\n",
                "        x = x_mb[:, i, :]\r\n",
                "        y = y_rnn[:, i+1, :]\r\n",
                "        y_prev = y_rnn[:, i, :]\r\n",
                "        grad_y = rnnLayer.backward(x, y, y_prev, grad_y + grad_x_out)\r\n",
                "\r\n",
                "    # update\r\n",
                "    rnnLayer.update(eta)\r\n",
                "    outputLayer.update(eta)\r\n",
                "    return y_out\r\n",
                "\r\n",
                "def get_error(y, t):\r\n",
                "    return 1.0/2.0*np.sum(np.square(y - t))\r\n",
                "\r\n",
                "for i in range(n_learn):\r\n",
                "    # create random\r\n",
                "    num1 = np.random.randint(max_num//2)\r\n",
                "    num2 = np.random.randint(max_num//2)\r\n",
                "\r\n",
                "    # input\r\n",
                "    x1= binaries[num1]\r\n",
                "    x2= binaries[num2]\r\n",
                "    x_in = np.zeros((1, n_time, n_in))\r\n",
                "    x_in[0, :, 0] = x1\r\n",
                "    x_in[0, :, 1] = x2\r\n",
                "    x_in  = np.flip(x_in, axis=1)\r\n",
                "\r\n",
                "    # create correct\r\n",
                "    t = binaries[num1+num2]\r\n",
                "    t_in = t.reshape(1, n_time, n_out)\r\n",
                "    t_in = np.flip(t_in , axis=1)\r\n",
                "\r\n",
                "    # learning\r\n",
                "    y_out = train(x_in, t_in)\r\n",
                "    y = np.flip(y_out, axis=1).reshape(-1)\r\n",
                "\r\n",
                "    error = get_error(y_out, t_in)\r\n",
                "\r\n",
                "    if i % interval == 0:\r\n",
                "        y2 = np.where(y<0.5, 0, 1)\r\n",
                "        y10 = 0\r\n",
                "        for j in range(len(y)):\r\n",
                "            pow2 = 2 ** (n_time-1-j)\r\n",
                "            y10 += y2[j] * pow2\r\n",
                "\r\n",
                "        print(\"learn count:\", i)\r\n",
                "        print(\"error rate:\", error)\r\n",
                "        print(\"output :\", y2)\r\n",
                "        print(\"correct:\", t)\r\n",
                "\r\n",
                "        c = \"Success : \" if (y2 == t).all() else \"Failure : \"\r\n",
                "        print(c + str(num1) + \" + \" + str(num2) + \" = \" + str(y10))\r\n",
                "        print(\"-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "n_learn: 0\n",
                        "error: 0.9337541878325495\n",
                        "output : [0 1 0 0 0 0 1 0]\n",
                        "correct: [0 1 0 0 0 0 0 1]\n",
                        "orz : 33 + 32 = 66\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "n_learn: 500\n",
                        "error: 0.6338173844864895\n",
                        "output : [1 1 1 1 0 1 1 1]\n",
                        "correct: [1 1 1 0 0 1 0 1]\n",
                        "orz : 107 + 122 = 247\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "n_learn: 1000\n",
                        "error: 0.08709147697811526\n",
                        "output : [1 0 1 0 1 1 0 1]\n",
                        "correct: [1 0 1 0 1 1 0 1]\n",
                        "\\(^_^)/ : 123 + 50 = 173\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "n_learn: 1500\n",
                        "error: 0.04121356644880319\n",
                        "output : [0 0 1 0 1 0 0 1]\n",
                        "correct: [0 0 1 0 1 0 0 1]\n",
                        "\\(^_^)/ : 18 + 23 = 41\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "n_learn: 2000\n",
                        "error: 0.018843175140588423\n",
                        "output : [1 1 0 0 0 0 1 1]\n",
                        "correct: [1 1 0 0 0 0 1 1]\n",
                        "\\(^_^)/ : 114 + 81 = 195\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "n_learn: 2500\n",
                        "error: 0.014113131401947657\n",
                        "output : [0 1 1 1 1 0 1 0]\n",
                        "correct: [0 1 1 1 1 0 1 0]\n",
                        "\\(^_^)/ : 93 + 29 = 122\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "n_learn: 3000\n",
                        "error: 0.021604009865586582\n",
                        "output : [1 0 1 0 0 1 0 0]\n",
                        "correct: [1 0 1 0 0 1 0 0]\n",
                        "\\(^_^)/ : 75 + 89 = 164\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "n_learn: 3500\n",
                        "error: 0.003113157440875398\n",
                        "output : [0 0 0 1 0 1 1 0]\n",
                        "correct: [0 0 0 1 0 1 1 0]\n",
                        "\\(^_^)/ : 18 + 4 = 22\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "n_learn: 4000\n",
                        "error: 0.0033545046578631063\n",
                        "output : [0 1 1 0 1 0 1 0]\n",
                        "correct: [0 1 1 0 1 0 1 0]\n",
                        "\\(^_^)/ : 106 + 0 = 106\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "n_learn: 4500\n",
                        "error: 0.017564774118878718\n",
                        "output : [0 0 1 0 0 0 0 0]\n",
                        "correct: [0 0 1 0 0 0 0 0]\n",
                        "\\(^_^)/ : 11 + 21 = 32\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
                        "n_learn: 5000\n",
                        "error: 0.005929084337274627\n",
                        "output : [1 1 0 0 1 0 1 1]\n",
                        "correct: [1 1 0 0 1 0 1 1]\n",
                        "\\(^_^)/ : 118 + 85 = 203\n",
                        "-- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.8 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "73e03da126b73bfff3642ec5261d56fa25c444ea595de51041687efaa60dda41"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}